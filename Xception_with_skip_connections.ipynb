{"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"Xception_pytorch.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"abb964e12a0c484f9ca2283b4d3b6ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_afefca8955d84f2490b85803d1475a86","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9d2de6d746644b7fa45bed2369510424","IPY_MODEL_351a7afa56334748a807ed0c4e76e762"]}},"afefca8955d84f2490b85803d1475a86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d2de6d746644b7fa45bed2369510424":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e477ba7734c24bbd8d0ab4ebf6eaa374","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1041eef6e9540dba74eade5d37f3851"}},"351a7afa56334748a807ed0c4e76e762":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ffd77bd3647949489baff9183e82fae0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"170500096it [00:30, 15909372.39it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_797c1c3c9f6647ed97ba8b81d21eadef"}},"e477ba7734c24bbd8d0ab4ebf6eaa374":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c1041eef6e9540dba74eade5d37f3851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffd77bd3647949489baff9183e82fae0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"797c1c3c9f6647ed97ba8b81d21eadef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport os\nimport glob\nimport PIL\nfrom PIL import Image\nfrom torch.utils import data as D\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport random","metadata":{"id":"7jBZ5w9065Pl","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T14:15:47.030826Z","iopub.execute_input":"2024-05-08T14:15:47.031208Z","iopub.status.idle":"2024-05-08T14:15:47.040721Z","shell.execute_reply.started":"2024-05-08T14:15:47.031177Z","shell.execute_reply":"2024-05-08T14:15:47.038069Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nvalidation_ratio = 0.1\nrandom_seed = 10","metadata":{"id":"uf3TCIeB65Pr","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T14:15:47.042821Z","iopub.execute_input":"2024-05-08T14:15:47.043869Z","iopub.status.idle":"2024-05-08T14:15:47.050472Z","shell.execute_reply.started":"2024-05-08T14:15:47.043828Z","shell.execute_reply":"2024-05-08T14:15:47.049343Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"transform_train = transforms.Compose([\n        transforms.Resize(299),\n        transforms.RandomCrop(299, padding=38),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntransform_validation = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\n\ntransform_test = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntrainset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_train)\n\nvalidset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_validation)\n\ntestset = torchvision.datasets.CIFAR10(\n    root='./data', train=False, download=True, transform=transform_test)\n\n#trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n#                                          shuffle=True, num_workers=0)\n\nnum_train = len(trainset)\nindices = list(range(num_train))\nsplit = int(np.floor(validation_ratio * num_train))\n\nnp.random.seed(random_seed)\nnp.random.shuffle(indices)\n\ntrain_idx, valid_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(\n    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    testset, batch_size=batch_size, shuffle=False, num_workers=0\n)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ninitial_lr = 0.045","metadata":{"id":"J164BT6q65Pv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["abb964e12a0c484f9ca2283b4d3b6ec4","afefca8955d84f2490b85803d1475a86","9d2de6d746644b7fa45bed2369510424","351a7afa56334748a807ed0c4e76e762","e477ba7734c24bbd8d0ab4ebf6eaa374","c1041eef6e9540dba74eade5d37f3851","ffd77bd3647949489baff9183e82fae0","797c1c3c9f6647ed97ba8b81d21eadef"]},"outputId":"4004b53c-d4a7-4903-9d82-76fe44552c8b","executionInfo":{"status":"ok","timestamp":1584338333889,"user_tz":-540,"elapsed":22685,"user":{"displayName":"hoya012","photoUrl":"https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg","userId":"15725788610401702262"}},"execution":{"iopub.status.busy":"2024-05-08T14:15:47.052260Z","iopub.execute_input":"2024-05-08T14:15:47.052556Z","iopub.status.idle":"2024-05-08T14:15:49.621380Z","shell.execute_reply.started":"2024-05-08T14:15:47.052530Z","shell.execute_reply":"2024-05-08T14:15:49.620273Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reduced Dataset","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as transforms\nimport torch\n\n# included_classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog']\nincluded_classes = ['plane', 'car', 'bird', 'cat', 'deer']\n\n\ntransform_train = transforms.Compose([\n        transforms.Resize(299),\n        transforms.RandomCrop(299, padding=38),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntransform_validation = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\n\ntransform_test = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntrainset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_train)\ntrainset = torch.utils.data.Subset(trainset, [idx for idx in range(len(trainset)) if trainset.targets[idx] < len(included_classes)])\n\nvalidset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_validation)\nvalidset = torch.utils.data.Subset(validset, [idx for idx in range(len(validset)) if validset.targets[idx] < len(included_classes)])\n\ntestset = torchvision.datasets.CIFAR10(\n    root='./data', train=False, download=True, transform=transform_test)\ntestset = torch.utils.data.Subset(testset, [idx for idx in range(len(testset)) if testset.targets[idx] < len(included_classes)])\n\nnum_train = len(trainset)\nindices = list(range(num_train))\nsplit = int(np.floor(validation_ratio * num_train))\n\nnp.random.seed(random_seed)\nnp.random.shuffle(indices)\n\ntrain_idx, valid_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(\n    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    testset, batch_size=batch_size, shuffle=False, num_workers=0\n)\n\nclasses = ('plane', 'car')\n\ninitial_lr = 0.045","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:15:49.622697Z","iopub.execute_input":"2024-05-08T14:15:49.622988Z","iopub.status.idle":"2024-05-08T14:15:52.162925Z","shell.execute_reply.started":"2024-05-08T14:15:49.622963Z","shell.execute_reply":"2024-05-08T14:15:52.162137Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass depthwise_separable_conv(nn.Module):\n    def __init__(self, nin, nout, kernel_size, padding, bias=False):\n        super(depthwise_separable_conv, self).__init__()\n        self.depthwise = nn.Conv2d(nin, nin, kernel_size=kernel_size, padding=padding, groups=nin, bias=bias)\n        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1, bias=bias)\n\n    def forward(self, x):\n        out = self.depthwise(x)\n        out = self.pointwise(out)\n        return out\n\nclass Xception(nn.Module):\n    def __init__(self, input_channel, num_classes=10):\n        super(Xception, self).__init__()\n        \n        # Entry flow with explicit skip connections\n        self.entry_flow_1 = nn.Sequential(\n            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n        \n        # Entry flow 2 with residual connection\n        self.entry_flow_2 = nn.Sequential(\n            depthwise_separable_conv(64, 128, 3, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            depthwise_separable_conv(128, 128, 3, 1),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_2_residual = nn.Conv2d(64, 128, kernel_size=1, stride=2, padding=0)\n        \n        # Entry flow 3 with residual connection\n        self.entry_flow_3 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(128, 256, 3, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            depthwise_separable_conv(256, 256, 3, 1),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_3_residual = nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=0)\n        \n        # Entry flow 4 with residual connection\n        self.entry_flow_4 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(256, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_4_residual = nn.Conv2d(256, 728, kernel_size=1, stride=2, padding=0)\n        \n        # Middle flow repeated 8 times with residual connections\n        self.middle_flow = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728)\n        )\n        \n        # Exit flow with explicit skip connections\n        self.exit_flow_1 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 1024, 3, 1),\n            nn.BatchNorm2d(1024),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.exit_flow_1_residual = nn.Conv2d(728, 1024, kernel_size=1, stride=2, padding=0)\n        self.exit_flow_2 = nn.Sequential(\n            depthwise_separable_conv(1024, 1536, 3, 1),\n            nn.BatchNorm2d(1536),\n            nn.ReLU(True),\n            depthwise_separable_conv(1536, 2048, 3, 1),\n            nn.BatchNorm2d(2048),\n            nn.ReLU(True)\n        )\n        \n        self.linear = nn.Linear(2048, num_classes)\n        \n    def forward(self, x):\n        # Apply each block, adding skip connections as defined\n        x = self.entry_flow_1(x)\n        x = self.entry_flow_2(x) + self.entry_flow_2_residual(x)\n        x = self.entry_flow_3(x) + self.entry_flow_3_residual(x)\n        x = self.entry_flow_4(x) + self.entry_flow_4_residual(x)\n        \n        # Middle flow iterations\n        middle_out = x\n        for _ in range(8):\n            middle_out = self.middle_flow(middle_out) + middle_out\n\n        x = self.exit_flow_1(middle_out) + self.exit_flow_1_residual(middle_out)\n        x = self.exit_flow_2(x)\n\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        output = self.linear(x)\n        \n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:15:52.164940Z","iopub.execute_input":"2024-05-08T14:15:52.165248Z","iopub.status.idle":"2024-05-08T14:15:52.190300Z","shell.execute_reply.started":"2024-05-08T14:15:52.165222Z","shell.execute_reply":"2024-05-08T14:15:52.189356Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Xception(nn.Module):\n    def __init__(self, input_channel, num_classes=10):\n        super(Xception, self).__init__()\n        \n        # Entry Flow\n        self.entry_flow_1 = nn.Sequential(\n            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True),\n            \n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True)\n        )\n        \n        self.entry_flow_2 = nn.Sequential(\n            depthwise_separable_conv(64, 128, 3, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            \n            depthwise_separable_conv(128, 128, 3, 1),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.entry_flow_2_residual = nn.Conv2d(64, 128, kernel_size=1, stride=2, padding=0)\n        \n        self.entry_flow_3 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(128, 256, 3, 1),\n            nn.BatchNorm2d(256),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(256, 256, 3, 1),\n            nn.BatchNorm2d(256),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.entry_flow_3_residual = nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=0)\n        \n        self.entry_flow_4 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(256, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.entry_flow_4_residual = nn.Conv2d(256, 728, kernel_size=1, stride=2, padding=0)\n        \n        # Middle Flow\n        self.middle_flow = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728)\n        )\n        \n        # Exit Flow\n        self.exit_flow_1 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 1024, 3, 1),\n            nn.BatchNorm2d(1024),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.exit_flow_1_residual = nn.Conv2d(728, 1024, kernel_size=1, stride=2, padding=0)\n        self.exit_flow_2 = nn.Sequential(\n            depthwise_separable_conv(1024, 1536, 3, 1),\n            nn.BatchNorm2d(1536),\n            nn.ReLU(True),\n            \n            depthwise_separable_conv(1536, 2048, 3, 1),\n            nn.BatchNorm2d(2048),\n            nn.ReLU(True)\n        )\n        \n        self.linear = nn.Linear(2048, num_classes)\n        \n    def forward(self, x):\n        entry_out1 = self.entry_flow_1(x)\n        entry_out2 = self.entry_flow_2(entry_out1) + self.entry_flow_2_residual(entry_out1)\n        entry_out3 = self.entry_flow_3(entry_out2) + self.entry_flow_3_residual(entry_out2)\n        entry_out = self.entry_flow_4(entry_out3) + self.entry_flow_4_residual(entry_out3)\n        \n        middle_out = self.middle_flow(entry_out) + entry_out\n        \n        for i in range(7):\n          middle_out = self.middle_flow(middle_out) + middle_out\n\n        exit_out1 = self.exit_flow_1(middle_out) + self.exit_flow_1_residual(middle_out)\n        exit_out2 = self.exit_flow_2(exit_out1)\n\n        exit_avg_pool = F.adaptive_avg_pool2d(exit_out2, (1, 1))                \n        exit_avg_pool_flat = exit_avg_pool.view(exit_avg_pool.size(0), -1)\n\n        output = self.linear(exit_avg_pool_flat)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:15:52.191821Z","iopub.execute_input":"2024-05-08T14:15:52.192104Z","iopub.status.idle":"2024-05-08T14:15:52.223477Z","shell.execute_reply.started":"2024-05-08T14:15:52.192079Z","shell.execute_reply":"2024-05-08T14:15:52.222659Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"net = Xception(3, 5) #ResNet-18","metadata":{"id":"850wCUVF65P7","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T14:15:52.224587Z","iopub.execute_input":"2024-05-08T14:15:52.224874Z","iopub.status.idle":"2024-05-08T14:15:52.317409Z","shell.execute_reply.started":"2024-05-08T14:15:52.224851Z","shell.execute_reply":"2024-05-08T14:15:52.316654Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Original Xception","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"id":"P5rgRS2565QA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"1f13fa0c-14cf-40db-9bbf-a2e19f80c9cb","executionInfo":{"status":"ok","timestamp":1584338342308,"user_tz":-540,"elapsed":768,"user":{"displayName":"hoya012","photoUrl":"https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg","userId":"15725788610401702262"}},"execution":{"iopub.status.busy":"2024-05-08T14:15:52.318587Z","iopub.execute_input":"2024-05-08T14:15:52.318889Z","iopub.status.idle":"2024-05-08T14:15:52.324436Z","shell.execute_reply.started":"2024-05-08T14:15:52.318864Z","shell.execute_reply":"2024-05-08T14:15:52.323416Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"net.to(device)","metadata":{"id":"K1nTbMKw65QD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"787b2db5-c6c9-409d-957c-651a6aba8a6a","executionInfo":{"status":"ok","timestamp":1584338352085,"user_tz":-540,"elapsed":9125,"user":{"displayName":"hoya012","photoUrl":"https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg","userId":"15725788610401702262"}},"execution":{"iopub.status.busy":"2024-05-08T14:15:52.325748Z","iopub.execute_input":"2024-05-08T14:15:52.326048Z","iopub.status.idle":"2024-05-08T14:15:52.352784Z","shell.execute_reply.started":"2024-05-08T14:15:52.326021Z","shell.execute_reply":"2024-05-08T14:15:52.351959Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Xception(\n  (entry_flow_1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (entry_flow_2): Sequential(\n    (0): depthwise_separable_conv(\n      (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n      (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): depthwise_separable_conv(\n      (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_2_residual): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n  (entry_flow_3): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n      (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_3_residual): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n  (entry_flow_4): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n      (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_4_residual): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2))\n  (middle_flow): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (exit_flow_1): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (exit_flow_1_residual): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2))\n  (exit_flow_2): Sequential(\n    (0): depthwise_separable_conv(\n      (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): depthwise_separable_conv(\n      (depthwise): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (linear): Linear(in_features=2048, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Define the number of epochs\nnum_epochs = 20\n\n# Outer loop over epochs\nfor epoch in range(num_epochs):\n    # Logic for adjusting learning rate every 2 epochs\n    if epoch == 0:\n        lr = initial_lr\n    elif epoch % 2 == 0 and epoch != 0:\n        lr *= 0.94\n        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n\n    # Initialize the running loss\n    running_loss = 0.0\n\n    # Wrap train_loader with tqdm to create a progress bar\n    with tqdm(train_loader, unit='batch') as t:\n        # Inner loop over batches\n        for i, data in enumerate(t):\n            # Get the inputs and labels\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n\n            # Update the running loss\n            running_loss += loss.item()\n\n            # Update the progress bar description\n            t.set_description(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / (i + 1):.4f}')\n\n    # Validation part\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, data in enumerate(valid_loader, 0):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = net(inputs)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    # Print accuracy after each epoch\n    print('[%d epoch] Accuracy of the network on the validation images: %d %%' %\n          (epoch, 100 * correct / total))\n\n# Print a message when finished training\nprint('Finished Training')\n","metadata":{"id":"8dALFTuL65QH","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T14:15:52.355169Z","iopub.execute_input":"2024-05-08T14:15:52.355452Z","iopub.status.idle":"2024-05-08T16:39:25.891029Z","shell.execute_reply.started":"2024-05-08T14:15:52.355427Z","shell.execute_reply":"2024-05-08T16:39:25.890129Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Epoch 1/20, Loss: 1.6352: 100%|██████████| 704/704 [06:55<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[0 epoch] Accuracy of the network on the validation images: 20 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20, Loss: 1.6352: 100%|██████████| 704/704 [06:54<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 epoch] Accuracy of the network on the validation images: 20 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20, Loss: 1.2508: 100%|██████████| 704/704 [06:54<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[2 epoch] Accuracy of the network on the validation images: 48 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20, Loss: 0.9558: 100%|██████████| 704/704 [06:54<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[3 epoch] Accuracy of the network on the validation images: 60 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20, Loss: 0.7844: 100%|██████████| 704/704 [06:54<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[4 epoch] Accuracy of the network on the validation images: 70 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20, Loss: 0.6533: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[5 epoch] Accuracy of the network on the validation images: 74 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20, Loss: 0.5405: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[6 epoch] Accuracy of the network on the validation images: 77 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20, Loss: 0.4786: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[7 epoch] Accuracy of the network on the validation images: 80 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20, Loss: 0.3990: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[8 epoch] Accuracy of the network on the validation images: 84 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20, Loss: 0.3641: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[9 epoch] Accuracy of the network on the validation images: 81 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20, Loss: 0.3157: 100%|██████████| 704/704 [06:54<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[10 epoch] Accuracy of the network on the validation images: 84 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20, Loss: 0.2919: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[11 epoch] Accuracy of the network on the validation images: 85 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20, Loss: 0.2589: 100%|██████████| 704/704 [06:54<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[12 epoch] Accuracy of the network on the validation images: 85 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20, Loss: 0.2397: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[13 epoch] Accuracy of the network on the validation images: 85 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20, Loss: 0.2144: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[14 epoch] Accuracy of the network on the validation images: 84 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20, Loss: 0.2017: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[15 epoch] Accuracy of the network on the validation images: 86 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20, Loss: 0.1798: 100%|██████████| 704/704 [06:54<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[16 epoch] Accuracy of the network on the validation images: 88 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20, Loss: 0.1696: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[17 epoch] Accuracy of the network on the validation images: 88 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20, Loss: 0.1561: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[18 epoch] Accuracy of the network on the validation images: 88 %\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20, Loss: 0.1474: 100%|██████████| 704/704 [06:53<00:00,  1.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[19 epoch] Accuracy of the network on the validation images: 89 %\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %d %%' % (\n    100 * correct / total))","metadata":{"id":"WM4hcitG65QO","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T16:39:25.892265Z","iopub.execute_input":"2024-05-08T16:39:25.892639Z","iopub.status.idle":"2024-05-08T16:39:59.442829Z","shell.execute_reply.started":"2024-05-08T16:39:25.892588Z","shell.execute_reply":"2024-05-08T16:39:59.441908Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test images: 89 %\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport time\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ncorrect = 0\ntotal = 0\nall_labels = []\nall_predictions = []\n\n# To measure inference time\nstart_time = time.time()\n\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        \n        # Forward pass to get outputs\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n\n        # Collect all labels and predictions for precision, recall, F1 score calculation\n        all_labels.extend(labels.cpu().numpy())\n        all_predictions.extend(predicted.cpu().numpy())\n\n        # Calculating correct predictions\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n# Calculate inference time\ninference_time = time.time() - start_time\n\n# Convert lists to numpy arrays for metric calculation\nall_labels = np.array(all_labels)\nall_predictions = np.array(all_predictions)\n\n# Calculate precision, recall, and F1 score\nprecision = precision_score(all_labels, all_predictions, average='macro')\nrecall = recall_score(all_labels, all_predictions, average='macro')\nf1 = f1_score(all_labels, all_predictions, average='macro')\n\nprint('Accuracy of the network on the test images: {:.2f} %'.format(100 * correct / total))\nprint('Precision: {:.4f}'.format(precision))\nprint('Recall: {:.4f}'.format(recall))\nprint('F1 Score: {:.4f}'.format(f1))\nprint('Inference Time: {:.2f} seconds'.format(inference_time))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:40:50.306344Z","iopub.execute_input":"2024-05-08T16:40:50.306708Z","iopub.status.idle":"2024-05-08T16:41:24.643437Z","shell.execute_reply.started":"2024-05-08T16:40:50.306676Z","shell.execute_reply":"2024-05-08T16:41:24.642526Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test images: 89.42 %\nPrecision: 0.8953\nRecall: 0.8942\nF1 Score: 0.8943\nInference Time: 33.75 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n                \n        for i in range(labels.shape[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))","metadata":{"id":"dYQ6TjYe65QR","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T16:39:59.443895Z","iopub.execute_input":"2024-05-08T16:39:59.444177Z","iopub.status.idle":"2024-05-08T16:40:33.093977Z","shell.execute_reply.started":"2024-05-08T16:39:59.444152Z","shell.execute_reply":"2024-05-08T16:40:33.092813Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Accuracy of plane : 90 %\nAccuracy of   car : 96 %\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m             class_total[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of \u001b[39m\u001b[38;5;132;01m%5s\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m%2d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m---> 19\u001b[0m         \u001b[43mclasses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m class_correct[i] \u001b[38;5;241m/\u001b[39m class_total[i]))\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"],"ename":"IndexError","evalue":"tuple index out of range","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"id":"yjkHTRvH65QU","colab_type":"code","colab":{}},"execution_count":null,"outputs":[]}]}