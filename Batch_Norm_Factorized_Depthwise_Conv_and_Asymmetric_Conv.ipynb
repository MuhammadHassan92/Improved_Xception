{"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"Xception_pytorch.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"abb964e12a0c484f9ca2283b4d3b6ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_afefca8955d84f2490b85803d1475a86","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9d2de6d746644b7fa45bed2369510424","IPY_MODEL_351a7afa56334748a807ed0c4e76e762"]}},"afefca8955d84f2490b85803d1475a86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d2de6d746644b7fa45bed2369510424":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e477ba7734c24bbd8d0ab4ebf6eaa374","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1041eef6e9540dba74eade5d37f3851"}},"351a7afa56334748a807ed0c4e76e762":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ffd77bd3647949489baff9183e82fae0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"170500096it [00:30, 15909372.39it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_797c1c3c9f6647ed97ba8b81d21eadef"}},"e477ba7734c24bbd8d0ab4ebf6eaa374":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c1041eef6e9540dba74eade5d37f3851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffd77bd3647949489baff9183e82fae0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"797c1c3c9f6647ed97ba8b81d21eadef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport os\nimport glob\nimport PIL\nfrom PIL import Image\nfrom torch.utils import data as D\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport random","metadata":{"id":"7jBZ5w9065Pl","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T15:32:32.241038Z","iopub.execute_input":"2024-05-08T15:32:32.241926Z","iopub.status.idle":"2024-05-08T15:32:39.066555Z","shell.execute_reply.started":"2024-05-08T15:32:32.241892Z","shell.execute_reply":"2024-05-08T15:32:39.065523Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nvalidation_ratio = 0.1\nrandom_seed = 10","metadata":{"id":"uf3TCIeB65Pr","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T15:32:39.068375Z","iopub.execute_input":"2024-05-08T15:32:39.069542Z","iopub.status.idle":"2024-05-08T15:32:39.073668Z","shell.execute_reply.started":"2024-05-08T15:32:39.069506Z","shell.execute_reply":"2024-05-08T15:32:39.072773Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transform_train = transforms.Compose([\n        transforms.Resize(299),\n        transforms.RandomCrop(299, padding=38),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntransform_validation = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\n\ntransform_test = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntrainset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_train)\n\nvalidset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_validation)\n\ntestset = torchvision.datasets.CIFAR10(\n    root='./data', train=False, download=True, transform=transform_test)\n\n#trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n#                                          shuffle=True, num_workers=0)\n\nnum_train = len(trainset)\nindices = list(range(num_train))\nsplit = int(np.floor(validation_ratio * num_train))\n\nnp.random.seed(random_seed)\nnp.random.shuffle(indices)\n\ntrain_idx, valid_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(\n    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    testset, batch_size=batch_size, shuffle=False, num_workers=0\n)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ninitial_lr = 0.045","metadata":{"id":"J164BT6q65Pv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["abb964e12a0c484f9ca2283b4d3b6ec4","afefca8955d84f2490b85803d1475a86","9d2de6d746644b7fa45bed2369510424","351a7afa56334748a807ed0c4e76e762","e477ba7734c24bbd8d0ab4ebf6eaa374","c1041eef6e9540dba74eade5d37f3851","ffd77bd3647949489baff9183e82fae0","797c1c3c9f6647ed97ba8b81d21eadef"]},"outputId":"4004b53c-d4a7-4903-9d82-76fe44552c8b","executionInfo":{"status":"ok","timestamp":1584338333889,"user_tz":-540,"elapsed":22685,"user":{"displayName":"hoya012","photoUrl":"https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg","userId":"15725788610401702262"}},"execution":{"iopub.status.busy":"2024-05-08T15:32:39.075327Z","iopub.execute_input":"2024-05-08T15:32:39.075853Z","iopub.status.idle":"2024-05-08T15:32:47.408399Z","shell.execute_reply.started":"2024-05-08T15:32:39.075818Z","shell.execute_reply":"2024-05-08T15:32:47.407497Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 46444069.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reduced Dataset","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as transforms\nimport torch\n\nincluded_classes = ['plane', 'car', 'bird', 'cat', 'deer']\n# included_classes = ['plane', 'car']\n\n\ntransform_train = transforms.Compose([\n        transforms.Resize(299),\n        transforms.RandomCrop(299, padding=38),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntransform_validation = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\n\ntransform_test = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n\ntrainset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_train)\ntrainset = torch.utils.data.Subset(trainset, [idx for idx in range(len(trainset)) if trainset.targets[idx] < len(included_classes)])\n\nvalidset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_validation)\nvalidset = torch.utils.data.Subset(validset, [idx for idx in range(len(validset)) if validset.targets[idx] < len(included_classes)])\n\ntestset = torchvision.datasets.CIFAR10(\n    root='./data', train=False, download=True, transform=transform_test)\ntestset = torch.utils.data.Subset(testset, [idx for idx in range(len(testset)) if testset.targets[idx] < len(included_classes)])\n\nnum_train = len(trainset)\nindices = list(range(num_train))\nsplit = int(np.floor(validation_ratio * num_train))\n\nnp.random.seed(random_seed)\nnp.random.shuffle(indices)\n\ntrain_idx, valid_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(\n    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    testset, batch_size=batch_size, shuffle=False, num_workers=0\n)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer')\n\ninitial_lr = 0.045","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:32:47.410304Z","iopub.execute_input":"2024-05-08T15:32:47.410597Z","iopub.status.idle":"2024-05-08T15:32:49.907954Z","shell.execute_reply.started":"2024-05-08T15:32:47.410571Z","shell.execute_reply":"2024-05-08T15:32:49.906967Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Proposed Paper Xception Model","metadata":{}},{"cell_type":"code","source":"class depthwise_separable_conv(nn.Module):\n    def __init__(self, nin, nout, kernel_size, padding, bias=False):\n        super(depthwise_separable_conv, self).__init__()\n        self.depthwise = nn.Conv2d(nin, nin, kernel_size=kernel_size, padding=padding, groups=nin, bias=bias)\n        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1, bias=bias)\n\n    def forward(self, x):\n        out = self.depthwise(x)\n        out = self.pointwise(out)\n        return out","metadata":{"id":"ObTXJ0dL65P1","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T15:32:49.909194Z","iopub.execute_input":"2024-05-08T15:32:49.909537Z","iopub.status.idle":"2024-05-08T15:32:49.916459Z","shell.execute_reply.started":"2024-05-08T15:32:49.909506Z","shell.execute_reply":"2024-05-08T15:32:49.915535Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Xception(nn.Module):\n    def __init__(self, input_channel, num_classes=10):\n        super(Xception, self).__init__()\n        \n        # Entry Flow\n        self.entry_flow_1 = nn.Sequential(\n            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True),\n            \n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True)\n        )\n        \n        self.entry_flow_2 = nn.Sequential(\n            depthwise_separable_conv(64, 128, 3, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            \n            depthwise_separable_conv(128, 128, 3, 1),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.entry_flow_2_residual = nn.Conv2d(64, 128, kernel_size=1, stride=2, padding=0)\n        \n        self.entry_flow_3 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(128, 256, 3, 1),\n            nn.BatchNorm2d(256),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(256, 256, 3, 1),\n            nn.BatchNorm2d(256),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.entry_flow_3_residual = nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=0)\n        \n        self.entry_flow_4 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(256, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.entry_flow_4_residual = nn.Conv2d(256, 728, kernel_size=1, stride=2, padding=0)\n        \n        # Middle Flow\n        self.middle_flow = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728)\n        )\n        \n        # Exit Flow\n        self.exit_flow_1 = nn.Sequential(\n            nn.ReLU(True),\n            depthwise_separable_conv(728, 728, 3, 1),\n            nn.BatchNorm2d(728),\n            \n            nn.ReLU(True),\n            depthwise_separable_conv(728, 1024, 3, 1),\n            nn.BatchNorm2d(1024),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.exit_flow_1_residual = nn.Conv2d(728, 1024, kernel_size=1, stride=2, padding=0)\n        self.exit_flow_2 = nn.Sequential(\n            depthwise_separable_conv(1024, 1536, 3, 1),\n            nn.BatchNorm2d(1536),\n            nn.ReLU(True),\n            \n            depthwise_separable_conv(1536, 2048, 3, 1),\n            nn.BatchNorm2d(2048),\n            nn.ReLU(True)\n        )\n        \n        self.linear = nn.Linear(2048, num_classes)\n        \n    def forward(self, x):\n        entry_out1 = self.entry_flow_1(x)\n        entry_out2 = self.entry_flow_2(entry_out1) + self.entry_flow_2_residual(entry_out1)\n        entry_out3 = self.entry_flow_3(entry_out2) + self.entry_flow_3_residual(entry_out2)\n        entry_out = self.entry_flow_4(entry_out3) + self.entry_flow_4_residual(entry_out3)\n        \n        middle_out = self.middle_flow(entry_out) + entry_out\n        \n        for i in range(7):\n          middle_out = self.middle_flow(middle_out) + middle_out\n\n        exit_out1 = self.exit_flow_1(middle_out) + self.exit_flow_1_residual(middle_out)\n        exit_out2 = self.exit_flow_2(exit_out1)\n\n        exit_avg_pool = F.adaptive_avg_pool2d(exit_out2, (1, 1))                \n        exit_avg_pool_flat = exit_avg_pool.view(exit_avg_pool.size(0), -1)\n\n        output = self.linear(exit_avg_pool_flat)\n        \n        return output","metadata":{"id":"8JNdBwbf65P4","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T15:32:49.917730Z","iopub.execute_input":"2024-05-08T15:32:49.918016Z","iopub.status.idle":"2024-05-08T15:32:49.942008Z","shell.execute_reply.started":"2024-05-08T15:32:49.917992Z","shell.execute_reply":"2024-05-08T15:32:49.941079Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"net = Xception(3, 10) #ResNet-18","metadata":{"id":"850wCUVF65P7","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T15:32:49.943328Z","iopub.execute_input":"2024-05-08T15:32:49.943630Z","iopub.status.idle":"2024-05-08T15:32:50.081297Z","shell.execute_reply.started":"2024-05-08T15:32:49.943604Z","shell.execute_reply":"2024-05-08T15:32:50.080477Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# IMPROVED XCEPTION MODEL V1","metadata":{}},{"cell_type":"markdown","source":"Using Batch Normalization and Factorized Convolutions","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ImprovedXception(nn.Module):\n    def __init__(self, input_channel, num_classes=10):\n        super(ImprovedXception, self).__init__()\n        \n        # Entry Flow\n        self.entry_flow_1 = nn.Sequential(\n            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True),\n            \n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True)\n        )\n        \n        self.entry_flow_2 = nn.Sequential(\n            depthwise_separable_conv(64, 128, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_2_residual = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(128)\n        )\n        \n        self.entry_flow_3 = nn.Sequential(\n            depthwise_separable_conv(128, 256, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_3_residual = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(256)\n        )\n        \n        self.entry_flow_4 = nn.Sequential(\n            depthwise_separable_conv(256, 728, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_4_residual = nn.Sequential(\n            nn.Conv2d(256, 728, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(728)\n        )\n        \n        # Middle Flow\n        self.middle_flow = nn.Sequential(\n            *[depthwise_separable_conv(728, 728, 3, 1, use_batchnorm=True) for _ in range(8)]\n        )\n        \n        # Exit Flow\n        self.exit_flow_1 = nn.Sequential(\n            depthwise_separable_conv(728, 1024, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.exit_flow_1_residual = nn.Sequential(\n            nn.Conv2d(728, 1024, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(1024)\n        )\n        self.exit_flow_2 = nn.Sequential(\n            depthwise_separable_conv(1024, 1536, 3, 1, use_batchnorm=True),\n            depthwise_separable_conv(1536, 2048, 3, 1, use_batchnorm=True)\n        )\n        \n        self.linear = nn.Linear(2048, num_classes)\n        \n    def forward(self, x):\n        x = self.entry_flow_1(x)\n        residual = self.entry_flow_2_residual(x)\n        x = self.entry_flow_2(x)\n        x = F.relu(x + residual)\n        \n        residual = self.entry_flow_3_residual(x)\n        x = self.entry_flow_3(x)\n        x = F.relu(x + residual)\n        \n        residual = self.entry_flow_4_residual(x)\n        x = self.entry_flow_4(x)\n        x = F.relu(x + residual)\n        \n        x = self.middle_flow(x)\n        \n        residual = self.exit_flow_1_residual(x)\n        x = self.exit_flow_1(x)\n        x = F.relu(x + residual)\n        \n        x = self.exit_flow_2(x)\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x\n\ndef depthwise_separable_conv(nin, nout, kernel_size, padding, use_batchnorm=False):\n    layers = [\n        nn.Conv2d(nin, nin, kernel_size=kernel_size, padding=padding, groups=nin, bias=not use_batchnorm),\n        nn.BatchNorm2d(nin) if use_batchnorm else nn.Identity(),\n        nn.ReLU(True),\n        nn.Conv2d(nin, nout, kernel_size=1, bias=not use_batchnorm),\n        nn.BatchNorm2d(nout) if use_batchnorm else nn.Identity(),\n        nn.ReLU(True)\n    ]\n    return nn.Sequential(*layers)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:32:56.069107Z","iopub.execute_input":"2024-05-08T15:32:56.069524Z","iopub.status.idle":"2024-05-08T15:32:56.091623Z","shell.execute_reply.started":"2024-05-08T15:32:56.069495Z","shell.execute_reply":"2024-05-08T15:32:56.090492Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"net1 = ImprovedXception(3, 10)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:32:56.620689Z","iopub.execute_input":"2024-05-08T15:32:56.621071Z","iopub.status.idle":"2024-05-08T15:32:56.728585Z","shell.execute_reply.started":"2024-05-08T15:32:56.621039Z","shell.execute_reply":"2024-05-08T15:32:56.727475Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Imporoved Xception Model V2","metadata":{}},{"cell_type":"markdown","source":"Using asymmetric conv","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ImprovedXception1(nn.Module):\n    def __init__(self, input_channel, num_classes=10):\n        super(ImprovedXception1, self).__init__()\n        \n        # Entry Flow\n        self.entry_flow_1 = nn.Sequential(\n            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True),\n            \n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True)\n        )\n        \n        self.entry_flow_2 = nn.Sequential(\n            depthwise_separable_conv(64, 128, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_2_residual = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(128)\n        )\n        \n        self.entry_flow_3 = nn.Sequential(\n            depthwise_separable_conv(128, 256, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_3_residual = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(256)\n        )\n        \n        self.entry_flow_4 = nn.Sequential(\n            depthwise_separable_conv(256, 728, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.entry_flow_4_residual = nn.Sequential(\n            nn.Conv2d(256, 728, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(728)\n        )\n        \n        # Middle Flow\n        self.middle_flow = nn.Sequential(\n            *[depthwise_separable_conv(728, 728, 3, 1, use_batchnorm=True) for _ in range(8)]\n        )\n        \n        # Exit Flow\n        self.exit_flow_1 = nn.Sequential(\n            depthwise_separable_conv(728, 1024, 3, 1, use_batchnorm=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        self.exit_flow_1_residual = nn.Sequential(\n            nn.Conv2d(728, 1024, kernel_size=1, stride=2, padding=0, bias=False),\n            nn.BatchNorm2d(1024)\n        )\n        self.exit_flow_2 = nn.Sequential(\n            depthwise_separable_conv(1024, 1536, 3, 1, use_batchnorm=True),\n            depthwise_separable_conv(1536, 2048, 3, 1, use_batchnorm=True)\n        )\n        \n        self.linear = nn.Linear(2048, num_classes)\n        \n    def forward(self, x):\n        x = self.entry_flow_1(x)\n        residual = self.entry_flow_2_residual(x)\n        x = self.entry_flow_2(x)\n        x = F.relu(x + residual)\n        \n        residual = self.entry_flow_3_residual(x)\n        x = self.entry_flow_3(x)\n        x = F.relu(x + residual)\n        \n        residual = self.entry_flow_4_residual(x)\n        x = self.entry_flow_4(x)\n        x = F.relu(x + residual)\n        \n        x = self.middle_flow(x)\n        \n        residual = self.exit_flow_1_residual(x)\n        x = self.exit_flow_1(x)\n        x = F.relu(x + residual)\n        \n        x = self.exit_flow_2(x)\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x\n\ndef depthwise_separable_conv(nin, nout, kernel_size, padding, use_batchnorm=False):\n    layers = [\n        nn.Conv2d(nin, nin, kernel_size=(kernel_size, 1), padding=(padding, 0), groups=nin, bias=not use_batchnorm),\n        nn.Conv2d(nin, nin, kernel_size=(1, kernel_size), padding=(0, padding), groups=nin, bias=not use_batchnorm),\n        nn.BatchNorm2d(nin) if use_batchnorm else nn.Identity(),\n        nn.ReLU(True),\n        nn.Conv2d(nin, nout, kernel_size=1, bias=not use_batchnorm),\n        nn.BatchNorm2d(nout) if use_batchnorm else nn.Identity(),\n        nn.ReLU(True)\n    ]\n    return nn.Sequential(*layers)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:32:57.912968Z","iopub.execute_input":"2024-05-08T15:32:57.913334Z","iopub.status.idle":"2024-05-08T15:32:57.936105Z","shell.execute_reply.started":"2024-05-08T15:32:57.913306Z","shell.execute_reply":"2024-05-08T15:32:57.935055Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"net2 = ImprovedXception1(3, 10)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:32:58.313953Z","iopub.execute_input":"2024-05-08T15:32:58.314408Z","iopub.status.idle":"2024-05-08T15:32:58.426409Z","shell.execute_reply.started":"2024-05-08T15:32:58.314378Z","shell.execute_reply":"2024-05-08T15:32:58.425554Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Original Xception","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"id":"P5rgRS2565QA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"1f13fa0c-14cf-40db-9bbf-a2e19f80c9cb","executionInfo":{"status":"ok","timestamp":1584338342308,"user_tz":-540,"elapsed":768,"user":{"displayName":"hoya012","photoUrl":"https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg","userId":"15725788610401702262"}},"execution":{"iopub.status.busy":"2024-05-08T15:32:58.964697Z","iopub.execute_input":"2024-05-08T15:32:58.965068Z","iopub.status.idle":"2024-05-08T15:32:58.997972Z","shell.execute_reply.started":"2024-05-08T15:32:58.965036Z","shell.execute_reply":"2024-05-08T15:32:58.996924Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"net.to(device)","metadata":{"id":"K1nTbMKw65QD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"787b2db5-c6c9-409d-957c-651a6aba8a6a","executionInfo":{"status":"ok","timestamp":1584338352085,"user_tz":-540,"elapsed":9125,"user":{"displayName":"hoya012","photoUrl":"https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg","userId":"15725788610401702262"}},"execution":{"iopub.status.busy":"2024-05-08T15:32:59.414654Z","iopub.execute_input":"2024-05-08T15:32:59.415670Z","iopub.status.idle":"2024-05-08T15:32:59.581064Z","shell.execute_reply.started":"2024-05-08T15:32:59.415634Z","shell.execute_reply":"2024-05-08T15:32:59.580129Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Xception(\n  (entry_flow_1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (entry_flow_2): Sequential(\n    (0): depthwise_separable_conv(\n      (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n      (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): depthwise_separable_conv(\n      (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_2_residual): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n  (entry_flow_3): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n      (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_3_residual): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n  (entry_flow_4): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n      (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_4_residual): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2))\n  (middle_flow): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (exit_flow_1): Sequential(\n    (0): ReLU(inplace=True)\n    (1): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU(inplace=True)\n    (4): depthwise_separable_conv(\n      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (exit_flow_1_residual): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2))\n  (exit_flow_2): Sequential(\n    (0): depthwise_separable_conv(\n      (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): depthwise_separable_conv(\n      (depthwise): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    )\n    (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (linear): Linear(in_features=2048, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Improved V1","metadata":{}},{"cell_type":"code","source":"device1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device1)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:33:00.734809Z","iopub.execute_input":"2024-05-08T15:33:00.735188Z","iopub.status.idle":"2024-05-08T15:33:00.740519Z","shell.execute_reply.started":"2024-05-08T15:33:00.735139Z","shell.execute_reply":"2024-05-08T15:33:00.739628Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"net1.to(device1)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:33:01.318493Z","iopub.execute_input":"2024-05-08T15:33:01.318849Z","iopub.status.idle":"2024-05-08T15:33:01.347258Z","shell.execute_reply.started":"2024-05-08T15:33:01.318820Z","shell.execute_reply":"2024-05-08T15:33:01.346187Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"ImprovedXception(\n  (entry_flow_1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (entry_flow_2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_2_residual): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (entry_flow_3): Sequential(\n    (0): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_3_residual): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (entry_flow_4): Sequential(\n    (0): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_4_residual): Sequential(\n    (0): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (middle_flow): Sequential(\n    (0): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (4): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (5): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (6): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (7): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (exit_flow_1): Sequential(\n    (0): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (exit_flow_1_residual): Sequential(\n    (0): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (exit_flow_2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n      (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (linear): Linear(in_features=2048, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Improved V2","metadata":{}},{"cell_type":"code","source":"device2 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device2)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:33:02.729231Z","iopub.execute_input":"2024-05-08T15:33:02.730205Z","iopub.status.idle":"2024-05-08T15:33:02.735336Z","shell.execute_reply.started":"2024-05-08T15:33:02.730167Z","shell.execute_reply":"2024-05-08T15:33:02.734236Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"net2.to(device2)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:33:03.063157Z","iopub.execute_input":"2024-05-08T15:33:03.063554Z","iopub.status.idle":"2024-05-08T15:33:03.092388Z","shell.execute_reply.started":"2024-05-08T15:33:03.063526Z","shell.execute_reply":"2024-05-08T15:33:03.091463Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"ImprovedXception1(\n  (entry_flow_1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (entry_flow_2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=64, bias=False)\n      (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=64, bias=False)\n      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_2_residual): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (entry_flow_3): Sequential(\n    (0): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=128, bias=False)\n      (1): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=128, bias=False)\n      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_3_residual): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (entry_flow_4): Sequential(\n    (0): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=256, bias=False)\n      (1): Conv2d(256, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=256, bias=False)\n      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (entry_flow_4_residual): Sequential(\n    (0): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (middle_flow): Sequential(\n    (0): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (4): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (5): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (6): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (7): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n  )\n  (exit_flow_1): Sequential(\n    (0): Sequential(\n      (0): Conv2d(728, 728, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=728, bias=False)\n      (1): Conv2d(728, 728, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=728, bias=False)\n      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (exit_flow_1_residual): Sequential(\n    (0): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (exit_flow_2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=1024, bias=False)\n      (1): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=1024, bias=False)\n      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(1536, 1536, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=1536, bias=False)\n      (1): Conv2d(1536, 1536, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=1536, bias=False)\n      (2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n      (4): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): ReLU(inplace=True)\n    )\n  )\n  (linear): Linear(in_features=2048, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Original","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9)\n\nfor epoch in range(25):  # 데이터셋을 수차례 반복합니다.\n    if epoch == 0:\n        lr = initial_lr\n    elif epoch % 2 == 0 and epoch != 0:\n        lr *= 0.94\n        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n    \n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \"\"\"\n        running_loss += loss.item()\n        \n        show_period = 250\n        if i % show_period == show_period-1:    # print every \"show_period\" mini-batches\n            print('[%d, %5d] loss: %.7f' %\n                  (epoch + 1, i + 1, running_loss / show_period))\n            running_loss = 0.0\n        \"\"\"\n        \n    #validation part\n    correct = 0\n    total = 0\n    for i, data in enumerate(valid_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = net(inputs)\n        \n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n          (epoch, 100 * correct / total)\n         )\n\nprint('Finished Training')","metadata":{"id":"8dALFTuL65QH","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2024-05-08T13:46:51.321316Z","iopub.execute_input":"2024-05-08T13:46:51.321717Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[0 epoch] Accuracy of the network on the validation images: 46 %\n[1 epoch] Accuracy of the network on the validation images: 55 %\n[2 epoch] Accuracy of the network on the validation images: 59 %\n[3 epoch] Accuracy of the network on the validation images: 65 %\n[4 epoch] Accuracy of the network on the validation images: 68 %\n[5 epoch] Accuracy of the network on the validation images: 76 %\n[6 epoch] Accuracy of the network on the validation images: 78 %\n[7 epoch] Accuracy of the network on the validation images: 78 %\n[8 epoch] Accuracy of the network on the validation images: 81 %\n[9 epoch] Accuracy of the network on the validation images: 80 %\n[10 epoch] Accuracy of the network on the validation images: 82 %\n[11 epoch] Accuracy of the network on the validation images: 82 %\n[12 epoch] Accuracy of the network on the validation images: 83 %\n","output_type":"stream"}]},{"cell_type":"code","source":"dataiter = iter(test_loader)\nimages, labels = next(dataiter)\nimages, labels = images.to(device), labels.to(device)\n\noutputs = net(images)\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(len(images))))","metadata":{"id":"2J2bpOsr65QL","colab_type":"code","colab":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %d %%' % (\n    100 * correct / total))","metadata":{"id":"WM4hcitG65QO","colab_type":"code","colab":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_correct = list(0. for i in range(5)) #changed from 10 to 5 classes\nclass_total = list(0. for i in range(5)) #changed from 10 to 5 classes\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n                \n        for i in range(labels.shape[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(5): #changed from 10 to 5 classes\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))","metadata":{"id":"dYQ6TjYe65QR","colab_type":"code","colab":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"yjkHTRvH65QU","colab_type":"code","colab":{}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Improved V1","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net1.parameters(), lr=initial_lr, momentum=0.9)\n\nfor epoch in range(20):  # 데이터셋을 수차례 반복합니다.\n    if epoch == 0:\n        lr = initial_lr\n    elif epoch % 2 == 0 and epoch != 0:\n        lr *= 0.94\n        optimizer = optim.SGD(net1.parameters(), lr=lr, momentum=0.9)\n    \n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device1), labels.to(device1)\n\n        optimizer.zero_grad()\n\n        outputs = net1(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \"\"\"\n        running_loss += loss.item()\n        \n        show_period = 250\n        if i % show_period == show_period-1:    # print every \"show_period\" mini-batches\n            print('[%d, %5d] loss: %.7f' %\n                  (epoch + 1, i + 1, running_loss / show_period))\n            running_loss = 0.0\n        \"\"\"\n        \n    #validation part\n    correct = 0\n    total = 0\n    for i, data in enumerate(valid_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device1), labels.to(device1)\n        outputs = net1(inputs)\n        \n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n          (epoch, 100 * correct / total)\n         )\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:33:10.902310Z","iopub.execute_input":"2024-05-08T15:33:10.903183Z","iopub.status.idle":"2024-05-08T16:39:19.015116Z","shell.execute_reply.started":"2024-05-08T15:33:10.903134Z","shell.execute_reply":"2024-05-08T16:39:19.014090Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[0 epoch] Accuracy of the network on the validation images: 62 %\n[1 epoch] Accuracy of the network on the validation images: 67 %\n[2 epoch] Accuracy of the network on the validation images: 72 %\n[3 epoch] Accuracy of the network on the validation images: 75 %\n[4 epoch] Accuracy of the network on the validation images: 76 %\n[5 epoch] Accuracy of the network on the validation images: 76 %\n[6 epoch] Accuracy of the network on the validation images: 80 %\n[7 epoch] Accuracy of the network on the validation images: 80 %\n[8 epoch] Accuracy of the network on the validation images: 81 %\n[9 epoch] Accuracy of the network on the validation images: 83 %\n[10 epoch] Accuracy of the network on the validation images: 84 %\n[11 epoch] Accuracy of the network on the validation images: 84 %\n[12 epoch] Accuracy of the network on the validation images: 85 %\n[13 epoch] Accuracy of the network on the validation images: 86 %\n[14 epoch] Accuracy of the network on the validation images: 85 %\n[15 epoch] Accuracy of the network on the validation images: 86 %\n[16 epoch] Accuracy of the network on the validation images: 85 %\n[17 epoch] Accuracy of the network on the validation images: 86 %\n[18 epoch] Accuracy of the network on the validation images: 86 %\n[19 epoch] Accuracy of the network on the validation images: 86 %\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"dataiter = iter(test_loader)\nimages, labels = next(dataiter)\nimages, labels = images.to(device1), labels.to(device1)\n\noutputs = net1(images)\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(len(images))))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:39:19.016713Z","iopub.execute_input":"2024-05-08T16:39:19.017007Z","iopub.status.idle":"2024-05-08T16:39:19.174856Z","shell.execute_reply.started":"2024-05-08T16:39:19.016983Z","shell.execute_reply":"2024-05-08T16:39:19.173924Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Predicted:    cat plane   car   cat   car plane  bird  deer  bird  deer plane  deer   cat  deer   car  deer plane   cat   cat   cat  bird   cat   cat  bird   car  bird   car  bird plane  bird   cat   cat\n","output_type":"stream"}]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device1), labels.to(device1)\n        outputs = net1(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %d %%' % (\n    100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:39:19.176066Z","iopub.execute_input":"2024-05-08T16:39:19.176440Z","iopub.status.idle":"2024-05-08T16:39:42.705415Z","shell.execute_reply.started":"2024-05-08T16:39:19.176406Z","shell.execute_reply":"2024-05-08T16:39:42.704413Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test images: 87 %\n","output_type":"stream"}]},{"cell_type":"code","source":"class_correct = list(0. for i in range(5)) #changed from 10 to 2 classes\nclass_total = list(0. for i in range(5)) #changed from 10 to 2 classes\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device1), labels.to(device1)\n        outputs = net1(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n                \n        for i in range(labels.shape[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(5): #changed from 10 to 2 classes\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:39:42.707040Z","iopub.execute_input":"2024-05-08T16:39:42.707307Z","iopub.status.idle":"2024-05-08T16:40:06.450787Z","shell.execute_reply.started":"2024-05-08T16:39:42.707284Z","shell.execute_reply":"2024-05-08T16:40:06.449898Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Accuracy of plane : 91 %\nAccuracy of   car : 90 %\nAccuracy of  bird : 84 %\nAccuracy of   cat : 85 %\nAccuracy of  deer : 83 %\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport time\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ncorrect = 0\ntotal = 0\nall_labels = []\nall_predictions = []\n\n# To measure inference time\nstart_time = time.time()\n\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device1), labels.to(device1)\n        \n        # Forward pass to get outputs\n        outputs = net1(images)\n        _, predicted = torch.max(outputs.data, 1)\n\n        # Collect all labels and predictions for precision, recall, F1 score calculation\n        all_labels.extend(labels.cpu().numpy())\n        all_predictions.extend(predicted.cpu().numpy())\n\n        # Calculating correct predictions\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n# Calculate inference time\ninference_time = time.time() - start_time\n\n# Convert lists to numpy arrays for metric calculation\nall_labels = np.array(all_labels)\nall_predictions = np.array(all_predictions)\n\n# Calculate precision, recall, and F1 score\nprecision = precision_score(all_labels, all_predictions, average='macro')\nrecall = recall_score(all_labels, all_predictions, average='macro')\nf1 = f1_score(all_labels, all_predictions, average='macro')\n\nprint('Accuracy of the network on the test images: {:.2f} %'.format(100 * correct / total))\nprint('Precision: {:.4f}'.format(precision))\nprint('Recall: {:.4f}'.format(recall))\nprint('F1 Score: {:.4f}'.format(f1))\nprint('Inference Time: {:.2f} seconds'.format(inference_time))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:04:39.375765Z","iopub.execute_input":"2024-05-08T18:04:39.376405Z","iopub.status.idle":"2024-05-08T18:05:02.925721Z","shell.execute_reply.started":"2024-05-08T18:04:39.376372Z","shell.execute_reply":"2024-05-08T18:05:02.924760Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test images: 87.14 %\nPrecision: 0.8752\nRecall: 0.8714\nF1 Score: 0.8722\nInference Time: 23.53 seconds\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imporved V2","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net2.parameters(), lr=initial_lr, momentum=0.9)\n\nfor epoch in range(20):  # 데이터셋을 수차례 반복합니다.\n    if epoch == 0:\n        lr = initial_lr\n    elif epoch % 2 == 0 and epoch != 0:\n        lr *= 0.94\n        optimizer = optim.SGD(net2.parameters(), lr=lr, momentum=0.9)\n    \n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device2), labels.to(device2)\n\n        optimizer.zero_grad()\n\n        outputs = net2(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \"\"\"\n        running_loss += loss.item()\n        \n        show_period = 250\n        if i % show_period == show_period-1:    # print every \"show_period\" mini-batches\n            print('[%d, %5d] loss: %.7f' %\n                  (epoch + 1, i + 1, running_loss / show_period))\n            running_loss = 0.0\n        \"\"\"\n        \n    #validation part\n    correct = 0\n    total = 0\n    for i, data in enumerate(valid_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device2), labels.to(device2)\n        outputs = net2(inputs)\n        \n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n          (epoch, 100 * correct / total)\n         )\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:52:11.766138Z","iopub.execute_input":"2024-05-08T16:52:11.766933Z","iopub.status.idle":"2024-05-08T18:02:45.232453Z","shell.execute_reply.started":"2024-05-08T16:52:11.766904Z","shell.execute_reply":"2024-05-08T18:02:45.231508Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[0 epoch] Accuracy of the network on the validation images: 74 %\n[1 epoch] Accuracy of the network on the validation images: 77 %\n[2 epoch] Accuracy of the network on the validation images: 79 %\n[3 epoch] Accuracy of the network on the validation images: 80 %\n[4 epoch] Accuracy of the network on the validation images: 81 %\n[5 epoch] Accuracy of the network on the validation images: 81 %\n[6 epoch] Accuracy of the network on the validation images: 83 %\n[7 epoch] Accuracy of the network on the validation images: 81 %\n[8 epoch] Accuracy of the network on the validation images: 82 %\n[9 epoch] Accuracy of the network on the validation images: 83 %\n[10 epoch] Accuracy of the network on the validation images: 84 %\n[11 epoch] Accuracy of the network on the validation images: 85 %\n[12 epoch] Accuracy of the network on the validation images: 83 %\n[13 epoch] Accuracy of the network on the validation images: 84 %\n[14 epoch] Accuracy of the network on the validation images: 85 %\n[15 epoch] Accuracy of the network on the validation images: 85 %\n[16 epoch] Accuracy of the network on the validation images: 86 %\n[17 epoch] Accuracy of the network on the validation images: 86 %\n[18 epoch] Accuracy of the network on the validation images: 85 %\n[19 epoch] Accuracy of the network on the validation images: 86 %\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"dataiter = iter(test_loader)\nimages, labels = next(dataiter)\nimages, labels = images.to(device2), labels.to(device2)\n\noutputs = net2(images)\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(len(images))))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:04:29.400872Z","iopub.execute_input":"2024-05-08T18:04:29.401845Z","iopub.status.idle":"2024-05-08T18:04:29.590879Z","shell.execute_reply.started":"2024-05-08T18:04:29.401799Z","shell.execute_reply":"2024-05-08T18:04:29.589870Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Predicted:    cat plane plane   cat   car plane plane  deer  bird  deer plane  deer   cat  deer   car  deer plane   cat  bird  deer  deer   cat   cat  bird   car  bird  deer  bird plane  bird   cat   cat\n","output_type":"stream"}]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device2), labels.to(device2)\n        outputs = net2(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %d %%' % (\n    100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:05:02.927694Z","iopub.execute_input":"2024-05-08T18:05:02.928090Z","iopub.status.idle":"2024-05-08T18:05:28.842398Z","shell.execute_reply.started":"2024-05-08T18:05:02.928054Z","shell.execute_reply":"2024-05-08T18:05:28.841238Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test images: 86 %\n","output_type":"stream"}]},{"cell_type":"code","source":"class_correct = list(0. for i in range(5)) #changed from 10 to 2 classes\nclass_total = list(0. for i in range(5)) #changed from 10 to 2 classes\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device2), labels.to(device2)\n        outputs = net2(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n                \n        for i in range(labels.shape[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(5): #changed from 10 to 2 classes\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:07:01.393037Z","iopub.execute_input":"2024-05-08T18:07:01.393781Z","iopub.status.idle":"2024-05-08T18:07:27.515761Z","shell.execute_reply.started":"2024-05-08T18:07:01.393748Z","shell.execute_reply":"2024-05-08T18:07:27.514747Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Accuracy of plane : 94 %\nAccuracy of   car : 89 %\nAccuracy of  bird : 75 %\nAccuracy of   cat : 84 %\nAccuracy of  deer : 89 %\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport time\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ncorrect = 0\ntotal = 0\nall_labels = []\nall_predictions = []\n\n# To measure inference time\nstart_time = time.time()\n\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device2), labels.to(device2)\n        \n        # Forward pass to get outputs\n        outputs = net2(images)\n        _, predicted = torch.max(outputs.data, 1)\n\n        # Collect all labels and predictions for precision, recall, F1 score calculation\n        all_labels.extend(labels.cpu().numpy())\n        all_predictions.extend(predicted.cpu().numpy())\n\n        # Calculating correct predictions\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n# Calculate inference time\ninference_time = time.time() - start_time\n\n# Convert lists to numpy arrays for metric calculation\nall_labels = np.array(all_labels)\nall_predictions = np.array(all_predictions)\n\n# Calculate precision, recall, and F1 score\nprecision = precision_score(all_labels, all_predictions, average='macro')\nrecall = recall_score(all_labels, all_predictions, average='macro')\nf1 = f1_score(all_labels, all_predictions, average='macro')\n\nprint('Accuracy of the network on the test images: {:.2f} %'.format(100 * correct / total))\nprint('Precision: {:.4f}'.format(precision))\nprint('Recall: {:.4f}'.format(recall))\nprint('F1 Score: {:.4f}'.format(f1))\nprint('Inference Time: {:.2f} seconds'.format(inference_time))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:07:27.517425Z","iopub.execute_input":"2024-05-08T18:07:27.517707Z","iopub.status.idle":"2024-05-08T18:07:53.333584Z","shell.execute_reply.started":"2024-05-08T18:07:27.517682Z","shell.execute_reply":"2024-05-08T18:07:53.332509Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test images: 86.70 %\nPrecision: 0.8717\nRecall: 0.8670\nF1 Score: 0.8668\nInference Time: 25.80 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}